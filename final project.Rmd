---
title: "final project"
author: "Haokun Zhang, Zhang Lu, Jonathan"
date: '2023-04-20'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
### Workflow
### 1. Define the question:  How much should we pay for Audit fee?
### 2. Data wrangling(Completed)
### 3. Data Visualization(EDA - Exploratory Data Analysis) 
### 4. Unsupervised learning: Use PCAmix and K-means++ clustering to do the company segmentation? Like 繼鵬他們做的)
### Then choose the model(Supervised learning): 
###     Linear regression, knn, Regression tree: random forest, CART, Boosting & Lasso regression
### 5. 學繼鵬：用lasso 和Random Forest兩個model，找出會影響audit fee的因素有哪些
### 6. Model training: Split to Training set & Testing set,  do the K-fold Cross-Validation
### 7. Assess the model performance: k-fold cv, MSE, R-square, F-1 score(the chart of actual and  predicted)
### ( Choose the best performance model，use it to do the prediction，並且將結果圖表化？ Partial dependence plots etc)
### 8. Conclusion: What did we learn- 根據不同的input value, 可以預測audit fee為多少


### Workflow if learn from other ppl
### 1~4 same
### 5. Use lasso regression and do th cv, find the important coefficients(more robust and understandable coefficients)
### 6. Use Random Forest to measure the variable importance(better fit but less interpretability), and use partial plots 
### End




## Problem zone
### 1. How to assess the model performance? BC Lasso model 好像不能用MSE去評價？ If not, what can we use to assess the model?
### 2. Model是要用來找出variable的重要性的嗎？ 繼鵬好像是用lasso 找出重要的 independent variable
### 繼鵬他們沒有用模型進行預測，只是針對數據分析結果做出解釋，提出哪些因素對acquire more kisses on dating app有影響
### 如果要學繼鵬他們，就是提出哪些因素對acquire more kisses有影響
### Step 5. : 像company name, city 這種變數該怎麼處理
### Step 6. Problem: lm, knn, lasso 的k-fold CV怎麼做

```{r cars}
# Step 2. Data wrangling & load the needed packages
## Loaded the needed packages

library(ggplot2)
library(caret)
library(car)
library(factoextra)
library(randomForest)
library(rfUtilities)
library(rsample)
library(multcomp) 

df <- read.csv("https://raw.githubusercontent.com/haokunz/Data_mining_project/main/data/internal_controls_data_0421.csv",
               header = TRUE)

# delete copyright and lines of notes
df <- df[-c(nrow(df), nrow(df)-1), ]

# remove records with restated internal control report
duplicated_indexes <- which(df$Restated.Internal.Control.Report == "Yes (1)")
duplicated_companies <- unique(df$Company[duplicated_indexes])
restate_indexes <- which(df$Company %in% duplicated_companies)
remove_index <- setdiff(restate_indexes, duplicated_indexes)
df1 <- df[-remove_index, ]

# remove duplicated records from different auditors working at the same time
multi_auditors <- table(df1$Company)[table(df1$Company) >= 2]
remove_index_2 <- setdiff(which(df1$Company %in% names(multi_auditors)), match(names(multi_auditors), df1$Company))
df2 <- df1[-remove_index_2, ]

# remove rows with missing revenue data
df2 <- df2[df2$Revenue.... != "", ]

# select target columns
df3 <- df2[ ,c("Company", "City", "State.Code", "State.Name", "State.Region", 
               "Auditor", "Auditor.Key", "Auditor.State.Name", 
               "Effective.Internal.Controls", "Audit.Fees....", "Non.Audit.Fees....",
               "Total.Fees....", "Share.Price", "Market.Cap....", "Revenue....",
               "Earnings....", "Book.Value....", "Assets....")]

# change column names to mark the targets
colnames(df3) <- c("company", "city", "state_code", "state_name", "state_region",
                   "auditor", "auditor_key", "auditor_state_name", 
                   "effective_internal_controls", "audit_fees", "non_audit_fees",
                   "total_fees", "share_price", "market_cap","revenue",
                   "earnings", "book_value", "assets")

# convert money amount character into numeric
df3$audit_fees = as.numeric(gsub(",", "", df3$audit_fees))
df3$non_audit_fees = as.numeric(gsub(",", "", df3$non_audit_fees))
df3$total_fees = as.numeric(gsub(",", "", df3$total_fees))
df3$market_cap = as.numeric(gsub(",", "", df3$market_cap))
df3$revenue = as.numeric(gsub(",", "", df3$revenue))
df3$earnings = as.numeric(gsub(",", "", df3$earnings))
df3$book_value = as.numeric(gsub(",", "", df3$book_value))
df3$assets = as.numeric(gsub(",", "", df3$assets))

# add indicator for analysis
df3$big_four_indicator <- ifelse(df3$auditor_key <= 4, 1, 0)
df3$five_category <- ifelse(df3$auditor_key < 5, df3$auditor_key, 5)
df3$audit_percent <- df3$audit_fees / df3$total_fees

# add transformation variables to the data
df3$audit_fees_bc <- predict(BoxCoxTrans(df3$audit_fees), df3$audit_fees)
non_audit_bc <- predict(BoxCoxTrans(df3$non_audit_fees[df3$non_audit_fees!=0]),
                        df3$non_audit_fees[df3$non_audit_fees!=0])
df3$total_fees_bc <- predict(BoxCoxTrans(df3$total_fees), df3$total_fees)
df3$market_cap_bc <- predict(BoxCoxTrans(df3$market_cap), df3$market_cap)
df3$market_fee_ratio <- log(df3$market_cap/ df3$total_fees)
df3$assets_log <- log(df3$assets)

revenue_0 = jitter(df3$revenue)
df3$revenue_trans <- (revenue_0/abs(revenue_0)) * log(abs(df3$revenue) + 1)

earnings_0 = jitter(df3$earnings)
df3$earnings_trans <- (earnings_0/abs(earnings_0)) * log(abs(df3$earnings) + 1)

# change columns to factors
df3$big_4_factor <- as.factor(df3$big_four_indicator)
df3$five_category_factor <- as.factor(df3$five_category)
df3$state_region <- as.factor(df3$state_region)

```

# Step 3. Data visualization(EDA - Exploratory Data Analysis) 
### Add the explanation for the chart
# basic plots, preliminary exploration #

```{r warning=FALSE, echo=FALSE, message=FALSE, alert=FALSE}
# plot the number distribution of companies in different regions
company_numbers <- sort(table(df3$state_region[df3$state_region != ""]), decreasing = FALSE, na.last = NA)

par(mar = c(5.1, 6.5, 4.1, 2.1))
barplot(height=company_numbers,
        names.arg=c("Canada", "US_NewEng", "US_Southwest", "US_Southeast",
                    "US_Midwest", "Foreign", "US_MAtlan", "US_West"),
        col="#69b3a2", horiz=TRUE, las = 1, main = "Num. of Companies", xlab = "numbers")
par(mar = c(5.1, 4.1, 4.1, 2.1))

# use eight plots to display the effect of transformation on fee related variables
par(mfrow = c(2, 4))
hist(df3$audit_fees, breaks="Scott", main="audit fees", xlab="Audit fees")
hist(df3$audit_fees_bc, main="audit fees (transformed)", xlab="Audit fees")
hist(df3$non_audit_fees, breaks="Scott", main="non audit fees", xlab="Non-audit fees")
hist(non_audit_bc, main="non audit fees (transformed)", xlab="Non-audit fees")
hist(df3$total_fees, breaks="Scott", main="total fees", xlab="Total fees")
hist(df3$total_fees_bc, main="total fees (transformed)", xlab="Total fees")
hist(df3$market_cap, breaks="Scott", main="Market cap", xlab="Market cap")
hist(df3$market_cap_bc, main="Market cap (transformed)", xlab="Market cap")
par(mfrow = c(1, 1))

# use three plots to display the categorical data
par(mfrow = c(1, 3))
barplot(table(df3$five_category_factor), ylab = "Frequency", main="Auditing company distribution")
barplot(table(df3$big_4_factor), yaxt='n', ylab="Frequency", main="Num. big4 vs. other")
axis(side=2, at=seq(0, nrow(df3), 200))
barplot(table(df3$effective_internal_controls), yaxt='n', ylab="Frequency", main="Num. effective internal controls")
axis(side=2, at=seq(0, nrow(df3), 200))
par(mfrow = c(1, 1))

# plot the transformed company market cap, total auditing fees, and effective internal control
sp = ggplot(df3, aes(x=market_cap_bc, y=five_category_factor,
                     group=effective_internal_controls)) +
     geom_point(aes(color=effective_internal_controls), size=0.9,
                    position=position_dodge2(0.3))

labels = as.vector(outer(rep("Num. of 'No'="), table(df3$effective_internal_controls,
                                           df3$five_category_factor)[1,],
                         paste, sep=""))
sp + annotate(geom="text", x=rep(27.5, 5), y=seq(0.7, 4.7, 1), label= labels) 

# plot the transformed company market cap vs. total auditing fees
ggplot(df3, aes(x=market_cap_bc, y=total_fees_bc, group=five_category_factor)) +
  geom_point(aes(color=five_category_factor), size=0.9)

cor(df3$market_cap_bc, df3$total_fees_bc)

# plot the auditing fees
ggplot(df3, aes(x=five_category_factor, y=total_fees_bc)) + 
  geom_violin(trim=FALSE, fill="gray")+
  labs(title="Auditing fees",x="category", y = "total fees")+
  geom_boxplot(width=0.3)+
  theme_classic()
# Change color by groups
dp <- ggplot(df3, aes(x=five_category_factor, y=total_fees_bc, fill=five_category_factor)) + 
  geom_violin(trim=FALSE)+
  geom_boxplot(width=0.3, fill="white")+
  labs(title="Plot of auditing fees",x="category", y = "total fees")
dp + theme_classic()
```

# Step 4. Unsupervised learning: Use PCAmix and K-means++ clustering to do the company segmentation
```{r }
df3$effective_internal_controls_factor = as.factor(ifelse(df3$effective_internal_controls == "No", 0, 1))

X.quanti <- splitmix(df3)$X.quanti %>% scale()
X.quali <- splitmix(df3)$X.quali
df3_pca <- PCAmix(X.quanti, X.quali, ndim=4, rename.level = TRUE, graph=FALSE)

df3_pca_scores = df3_pca$ind$coord %>% as.data.frame()

# append 4 pc to df3
df3$PC1 <- df3_pca_scores$`dim 1`
df3$PC2 <- df3_pca_scores$`dim 2`
df3$PC3 <- df3_pca_scores$`dim 3`
df3$PC4 <- df3_pca_scores$`dim 4`

# perform analysis of variance for 1-5 auditing company levels
m5_ancova = lm(total_fees_bc ~ five_category_factor + market_cap_bc +
              five_category_factor*market_cap_bc, df3)
Anova(m5_ancova, type=3)

multi_comarisons <- lm(total_fees_bc ~ five_category_factor + market_cap_bc, df3)
postHocs <- glht(multi_comarisons, linfct=mcp(five_category_factor="Tukey"))
summary(postHocs)
plot(postHocs)

set.seed(143)
pca_data = na.omit(df3[ ,c("audit_fees_bc", "total_fees_bc", "market_cap_bc",
                           "market_fee_ratio", "assets_log", "revenue_trans",
                           "earnings_trans")])

gap_stat <- clusGap(pca_data, FUN = kmeans, nstart = 25,
                    K.max = 10, B = 50)
print(gap_stat, method = "firstmax")
fviz_gap_stat(gap_stat)

# k2 <- kmeans(pca_data, centers=2, nstart=25)
# k3 <- kmeans(pca_data, centers=3, nstart=25)
# k4 <- kmeans(pca_data, centers=4, nstart=25)
# k5 <- kmeans(pca_data, centers=5, nstart=25)
# k6 <- kmeans(pca_data, centers=6, nstart=25)
# k7 <- kmeans(pca_data, centers=7, nstart=25)

# fviz_cluster(k2, data=pca_data)
# fviz_cluster(k3, data=pca_data)
# fviz_cluster(k4, data=pca_data)
# fviz_cluster(k5, data=pca_data)
# fviz_cluster(k6, data=pca_data)
# fviz_cluster(k7, data=pca_data)


km.res <- kmeans(pca_data, 2, nstart=25)

aggregate(pca_data, by=list(cluster=km.res$cluster), mean)

dd <- cbind(pca_data, cluster=km.res$cluster)
head(dd)
fviz_cluster(km.res, data=pca_data)
# KClustering
## Choose optimal K - CH index
# k_grid = seq(2, 6, by=1)
# set.seed(8964)
#df_CH_grid = foreach(k=k_grid, .combine='rbind') %do% {
#  cluster_k = kmeanspp(df3_pca_scores, k, nstart = 50)
#  W = cluster_k$tot.withinss
#  B = cluster_k$betweenss
  # Use Calinski-Harabasz index to determine K
  # The  higher the better 
#  CH = (B/W)*((nrow(df3_pca_scores)-k)/(k-1)) 
#  c(k=k, stat = CH)
#} %>% as.data.frame()

#df_kmpp = kmeanspp(df3_pca_scores, k=5, nstart=25)
#df3$cluster = df_kmpp$cluster 

## Analysis
### Find out significant differences among groups
### Ans:  CH index suggests that optimal k = 5
# group 1+4 vs. 5
#clus1 = ggplot(df3) +
#  geom_point(aes(x=df3$market_cap_bc, y=df3$audit_fees, color=factor(cluster))) +
#  labs(color='Cluster')
# group 2: low conversion, high count details
#clus2 = ggplot(df3) +
#  geom_point(aes(x=df3$big_four_indicator, y=df3$audit_fees, color=factor(cluster))) +
#  labs(color='Cluster')
#ggarrange(clus1, clus2, common.legend = TRUE,
 #         legend = "bottom")

```
# Step 5. 用lasso (已删除) 和Random Forest兩個model，找出會影響audit fee的因素有哪些
## for gamlr, and many other fitting functions,
## We need to create the specific numeric feature matrix.
```{r warning=FALSE, echo=FALSE, message=FALSE, alert=FALSE}
# Step 5. 用lasso 和Random Forest兩個model，找出會影響audit fee的因素有哪些
# imoute the n.a. value
#imputeaudit <- knnImputation(df3, k = 100, scale = T, meth = "median", distData = NULL)

### Random Forest
df3_split = initial_split(df3, prop = 0.7)
df3_train = training(df3_split)
df3_test = testing(df3_split)
df3_train <- na.omit(df3_train)
##
auditfee_rforest = randomForest(audit_fees_bc ~ . - company -auditor_key - effective_internal_controls
                                - auditor - auditor_state_name -audit_fees -market_cap -revenue -total_fees_bc
                                -total_fees -non_audit_fees -assets -five_category -big_four_indicator -earnings
                                -state_region -market_fee_ratio -cluster,
                                data = df3_train, importance = TRUE)
# shows out-of-bag MSE as a function of the number of trees used
# plot(lvforest)
plot(auditfee_rforest)

# variable importance measures
# how much does mean-squared error increase when we ignore a variable?
vi = varImpPlot(auditfee_rforest)

# The upper chart shows that the x axis represents percentage increase in mean square error and the y axis represents different variables.

# Then we study the partial importance of each variable by eyeballing Figure
# partial dependence plots
# these are trying to isolate the partial effect of specific features
# on the outcome
#partialPlot(auditfee_rforest, df3_test, 'age', main=paste("") , las=1)
#partialPlot(auditfee_rforest, df3_test, 'counts_pictures', main=paste("") , las=1)

#partialPlot(auditfee_rforest, df3_test, 'lang_fr', main=paste("") ,las=1)
#partialPlot(auditfee_rforest, df3_test, 'lang_de', main=paste("") , las=1)
#partialPlot(auditfee_rforest, df3_test, 'countDetails', main=paste("") , las=1)
#partialPlot(auditfee_rforest, df3_test, 'freshman', main=paste("") , las=1)


```
### Write the explanation of step 5

```{r warning=FALSE, echo=FALSE, message=FALSE, alert=FALSE}
# Step 6. Model training: Linear regression, knn, Regression tree: random forest, CART, Boosting
### Problem: 像company name, city 這種變數該怎麼處理
# Split the dataset to training set & testing set
# df3_split = initial_split(df3, prop = 0.7)
# df3_train = training(df3_split)
# df3_test = testing(df3_split)

### Base model: Linear regression(Base model)
## Syntax: lm3 = lm(price ~ (. - pctCollege - sewer - waterfront - landValue - newConstruction)^2, data=saratoga_train)
tc <- trainControl(method="cv", number=5)
lm_cv <- train(total_fees_bc ~ five_category_factor + state_region + 
                 market_cap_bc + assets_log + revenue_trans + earnings_trans, data=df3,
               method="lm", trControl=tc)

### Model 2: KNN
## Syntax: KNN with K = 70
## knn100 = knnreg(COAST ~ KHOU, data=loadhou_train, k=100)
### modelr::rmse(knn100, loadhou_test)
## predict(knn100, loadhou_test)
knn_cv <- train(total_fees_bc ~ five_category_factor + state_region + 
                  market_cap_bc + assets_log + revenue_trans + earnings_trans, data=df3,
                method="knn", trControl=tc, tuneLength=20)

### Model 3 to 5 are belong to regression trees
### Syntax in Exercise3 Q2
### Model 3: Random Forest model
## Syntax: rforest_dengue = randomForest(total_cases ~ .,data = dengue_training, importance=TRUE)
## Performance: Use rmse. Syntax: rmse(gbm_dengue, dengue_testing)
rf_cv <- train(total_fees_bc ~ five_category_factor + state_region + 
                 market_cap_bc + assets_log + revenue_trans + earnings_trans, data=df3,
               method="rf", trControl=tc, tuneLength=10)

### Model 4: CART model 
## Syntax: cart_dengue = rpart(total_cases ~ . , data = dengue_training, control = rpart.control(cp = 0.002, minsplit=20))
## Split only if we have at least 20 obs in a node,
## and the split improves the fit by a factor of 0.002 aka 0.2%
## Performance: Use rmse. Syntax: rmse(gbm_dengue, dengue_testing)
cart_cv <- train(total_fees_bc ~ five_category_factor + state_region + 
                   market_cap_bc + assets_log + revenue_trans + earnings_trans, data=df3,
                 method="rpart", trControl=tc, tuneLength=10)

### Model 5: Gradient-boosted model
## in the "capmetro.R"
## Syntax: gbm_dengue = gbm(total_cases ~ ., data = dengue_training, interaction.depth=4, n.trees=500, shrinkage=.05)
## Performance: Use rmse. Syntax: rmse(gbm_dengue, dengue_testing)
gbm_cv <- train(total_fees_bc ~ five_category_factor + state_region + 
                  market_cap_bc + assets_log + revenue_trans + earnings_trans, data=df3,
                method="gbm", trControl=tc, tuneLength=10, verbose=FALSE)

model_list <- list(lm = lm_cv, knn = knn_cv, rf = rf_cv, cart = cart_cv, gbm = gbm_cv)
res = resamples(model_list)
summary(res)

### Model 6: Lasso regression
### Use lasso to find the important variables?
## 好像不能用MSE out of sample去評價，要用AIC？
## Syntax in homework exercise 2 
## Syntax for Lasso: 
### lasso_selected = glm(children ~ (.-arrival_date-deposit_type) + hotel:reserved_room_type+ meal:is_repeated_guest+ adults:previous_bookings_not_canceled+ meal:previous_bookings_not_canceled+ market_segment:customer_type+is_repeated_guest:assigned_room_type+ assigned_room_type:required_car_parking_spaces, data = hotels_dev_train, family = "binomial")

# for gamlr, and many other fitting functions,
# we need to create specific numeric feature matrix for it.
# auditx = model.matrix(audit_fees ~ .-1, data=df3_train)
# audity = df3$audit_fee
# # Without the AIC approximation: CV Lasso
# Syntax: lvcvl1 = cv.gamlr(lvx, lvy, nfold=10, standardize=FALSE,family="poisson"
# auditfee_cvl = cv.gamlr(auditx, audity, nfold = 10, standardize = FALSE, family = "poisson")
#  error: nrow(x) == n is not TRUE
## may bc of the y is not a numeric/ factor vector, but a dataframe
## maybe solve the problem "像company name, city 這種變數該怎麼處理", we can figure out this

```
### Step 7. 評價模型: K-fold Cross-validation
## Problem: lm, knn, lasso 的k-fold CV怎麼做
## Syntax in HW 3
## K-fold Cross-validation: (k-1) is training set, 1 is testing set
## 從沒當過testing set的 dataset中挑一個來做testing set, 剛剛做過testing set 的那份則加回去做training set
## repeat the step until every set 都當過testing set ## 會執行k次, 得到k個 validation error
## Average the k validation error, then we can know which model is better
```{r warning=FALSE, echo=FALSE, message=FALSE, alert=FALSE}
## evaluate the performance of the models by k-folds
## perform cross-validation
# predict the total auditing fee based on other variables
set.seed(2501)
data_split = initial_split(df3, prop=0.8)
data_train = training(data_split)
data_test = testing(data_split)

rf1 <- randomForest(total_fees_bc ~ five_category_factor + state_region + 
                      market_cap_bc + assets_log + revenue_trans + earnings_trans,
                    data=data_train, importance=TRUE)

rf1
plot(rf1)
modelr::rmse(rf1, data_test)
varImpPlot(rf1, type=1)
rf_predict <- predict(rf1, data_test)

RSQUARE = function(y_actual,y_predict){
  cor(y_actual,y_predict)^2
}

R2 <- RSQUARE(data_test$audit_fees_bc, rf_predict)


# plot predicted vs. actual values
plot(x=rf_predict, y= data_test$audit_fees_bc, xlab="Predicted Values",
     ylab="Actual Values", main="Predicted vs. Actual Values")

# add diagonal line for estimated regression line
abline(a=0, b=1)
mylabel =  bquote(italic(R)^2 == .(format(R2, digits = 3)))
legend("topleft", legend=mylabel)

# We will know that which model has the lowest MSE

```

